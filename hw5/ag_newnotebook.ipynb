{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "dataset = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "data_text = model.encode(dataset['train']['text'])\n",
    "\n",
    "data_label = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108000, 768)\n"
     ]
    }
   ],
   "source": [
    "val_text = data_text[108000:]\n",
    "train_text = data_text[:108000]\n",
    "\n",
    "val_label = data_label[108000:]\n",
    "train_label = data_label[:108000]\n",
    "print(train_text.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dense'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/john/Documents/DeepLearning/hw5/ag_newnotebook.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/john/Documents/DeepLearning/hw5/ag_newnotebook.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/john/Documents/DeepLearning/hw5/ag_newnotebook.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDropout\u001b[39;00m \u001b[39mimport\u001b[39;00m DropLayer\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/john/Documents/DeepLearning/hw5/ag_newnotebook.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDense\u001b[39;00m \u001b[39mimport\u001b[39;00m DenseLayer\n",
      "File \u001b[0;32m~/Documents/DeepLearning/hw5/sequential.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m trange\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdense\u001b[39;00m \u001b[39mimport\u001b[39;00m DenseLayer\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDropout\u001b[39;00m \u001b[39mimport\u001b[39;00m DropLayer\n\u001b[1;32m      8\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSequential\u001b[39;00m(tf\u001b[39m.\u001b[39mModule):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dense'"
     ]
    }
   ],
   "source": [
    "from sequential import Sequential\n",
    "from Dropout import DropLayer\n",
    "from Dense import DenseLayer\n",
    "model_mlp = Sequential([\n",
    "    DenseLayer(768, 256, activation=tf.nn.relu),\n",
    "    DropLayer(0.45),\n",
    "    DenseLayer(256,512, activation=tf.nn.relu),\n",
    "    DropLayer(0.45),\n",
    "    DenseLayer(512, 4, initializer=tf.zeros)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(labels, logits):\n",
    "    return tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits)\n",
    "    )\n",
    "def get_accuracy(correct_label, est_output):\n",
    "    model_mlp.isTrain = False\n",
    "    est_output = tf.math.argmax(est_output, axis=1)\n",
    "    num_correct = tf.equal(est_output, correct_label)\n",
    "    accuracy = tf.reduce_mean(tf.cast(num_correct, tf.float32)) * 100.0\n",
    "    model_mlp.isTrain = True\n",
    "    return accuracy\n",
    "\n",
    "from AdamW import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_custom = AdamW(learning_rate = 0.01, weight_decay=0.02)\n",
    "rng = tf.random.get_global_generator()\n",
    "rng.reset_from_seed(0x43966E87BD57227011B5B03B58785EC1)\n",
    "model_mlp.train_model(optimizer_custom, train_text, train_label, val_text, val_label, 1200, get_accuracy, get_loss, rng )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model_keras = tf.keras.Sequential(layers=[\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.45, seed=3489024),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.45, seed=3489024),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "\n",
    "model_keras.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(dataset['train']['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=0.01,weight_decay=0.02)\n",
    "model_keras.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "model_keras.fit(data_text, data_label, validation_split=0.10, epochs=10, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(dataset['test']['label'])\n",
    "data_test = model.encode(dataset['test']['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.evaluate(data_test, y_test)\n",
    "print(\"non-keras accuracy: \", get_accuracy(y_test, model_mlp(data_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
